{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8bba41",
   "metadata": {},
   "source": [
    "# Data Prep for Kaggle Spam Data - EDA, Data Cleansing, Text Pre-Processing, and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50527a9",
   "metadata": {},
   "source": [
    "### Kaggle Database Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706802f",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe9f8d",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0d7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import opendatasets as od\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, confusion_matrix, jaccard_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from keras.layers import SimpleRNN, LSTM, Dense, Dropout, Activation, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd5edb",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f49d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 5)\n"
     ]
    }
   ],
   "source": [
    "#loading corpus into data frame\n",
    "df = pd.read_csv(\"Data/spam.csv\", encoding = \"ISO-8859-1\", engine = \"python\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e761be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581847bc",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9844f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd168c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your free ringtone is waiting to be collected....</td>\n",
       "      <td>PO Box 5249</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\Wen u miss someone</td>\n",
       "      <td>the person is definitely special for u..... B...</td>\n",
       "      <td>why to miss them</td>\n",
       "      <td>just Keep-in-touch\\\" gdeve..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...</td>\n",
       "      <td>HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac sun0819 posts HELLO:\\You seem cool</td>\n",
       "      <td>wanted to say hi. HI!!!\\\" Stop? Send STOP to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>this wont even start........ Datz confidence..\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2  \\\n",
       "95   spam  Your free ringtone is waiting to be collected....   \n",
       "281   ham                                \\Wen u miss someone   \n",
       "444   ham  \\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...   \n",
       "671  spam         SMS. ac sun0819 posts HELLO:\\You seem cool   \n",
       "710   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "\n",
       "                                            Unnamed: 2             Unnamed: 3  \\\n",
       "95                                         PO Box 5249   MK17 92H. 450Ppw 16\"   \n",
       "281   the person is definitely special for u..... B...       why to miss them   \n",
       "444   HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE ...                    NaN   \n",
       "671   wanted to say hi. HI!!!\\\" Stop? Send STOP to ...                    NaN   \n",
       "710    this wont even start........ Datz confidence..\"                    NaN   \n",
       "\n",
       "                         Unnamed: 4  \n",
       "95                              NaN  \n",
       "281   just Keep-in-touch\\\" gdeve..\"  \n",
       "444                             NaN  \n",
       "671                             NaN  \n",
       "710                             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the data in the unnamed columns\n",
    "df[df['Unnamed: 2'].isnull() == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36af2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your free ringtone is waiting to be collected....</td>\n",
       "      <td>PO Box 5249</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\Wen u miss someone</td>\n",
       "      <td>the person is definitely special for u..... B...</td>\n",
       "      <td>why to miss them</td>\n",
       "      <td>just Keep-in-touch\\\" gdeve..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your free ringtone is waiting to be collected....</td>\n",
       "      <td>PO Box 5249</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>ham</td>\n",
       "      <td>Edison has rightly said, \\A fool can ask more ...</td>\n",
       "      <td>GN</td>\n",
       "      <td>GE</td>\n",
       "      <td>GNT:-)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER...</td>\n",
       "      <td>JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIG...</td>\n",
       "      <td>U NO THECD ISV.IMPORTANT TOME 4 2MORO\\\"\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  \\\n",
       "95    spam  Your free ringtone is waiting to be collected....   \n",
       "281    ham                                \\Wen u miss someone   \n",
       "899   spam  Your free ringtone is waiting to be collected....   \n",
       "1038   ham  Edison has rightly said, \\A fool can ask more ...   \n",
       "2170   ham  \\CAN I PLEASE COME UP NOW IMIN TOWN.DONTMATTER...   \n",
       "\n",
       "                                             Unnamed: 2  \\\n",
       "95                                          PO Box 5249   \n",
       "281    the person is definitely special for u..... B...   \n",
       "899                                         PO Box 5249   \n",
       "1038                                                 GN   \n",
       "2170  JUST REALLYNEED 2DOCD.PLEASE DONTPLEASE DONTIG...   \n",
       "\n",
       "                                    Unnamed: 3                      Unnamed: 4  \n",
       "95                        MK17 92H. 450Ppw 16\"                             NaN  \n",
       "281                           why to miss them   just Keep-in-touch\\\" gdeve..\"  \n",
       "899                       MK17 92H. 450Ppw 16\"                             NaN  \n",
       "1038                                        GE                         GNT:-)\"  \n",
       "2170  U NO THECD ISV.IMPORTANT TOME 4 2MORO\\\"\"                             NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Unnamed: 3'].isnull() == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b13b3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\Wen u miss someone</td>\n",
       "      <td>the person is definitely special for u..... B...</td>\n",
       "      <td>why to miss them</td>\n",
       "      <td>just Keep-in-touch\\\" gdeve..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>ham</td>\n",
       "      <td>Edison has rightly said, \\A fool can ask more ...</td>\n",
       "      <td>GN</td>\n",
       "      <td>GE</td>\n",
       "      <td>GNT:-)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>ham</td>\n",
       "      <td>I just lov this line: \\Hurt me with the truth</td>\n",
       "      <td>I don't mind</td>\n",
       "      <td>i wil tolerat.bcs ur my someone..... But</td>\n",
       "      <td>Never comfort me with a lie\\\" gud ni8 and swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
       "      <td>HAD A COOL NYTHO</td>\n",
       "      <td>TX 4 FONIN HON</td>\n",
       "      <td>CALL 2MWEN IM BK FRMCLOUD 9! J X\\\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>ham</td>\n",
       "      <td>When I was born, GOD said, \\Oh No! Another IDI...</td>\n",
       "      <td>GOD said</td>\n",
       "      <td>\\\"OH No! COMPETITION\\\". Who knew</td>\n",
       "      <td>one day these two will become FREINDS FOREVER!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2  \\\n",
       "281   ham                                \\Wen u miss someone   \n",
       "1038  ham  Edison has rightly said, \\A fool can ask more ...   \n",
       "2255  ham      I just lov this line: \\Hurt me with the truth   \n",
       "3525  ham  \\HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...   \n",
       "4668  ham  When I was born, GOD said, \\Oh No! Another IDI...   \n",
       "\n",
       "                                             Unnamed: 2  \\\n",
       "281    the person is definitely special for u..... B...   \n",
       "1038                                                 GN   \n",
       "2255                                       I don't mind   \n",
       "3525                                   HAD A COOL NYTHO   \n",
       "4668                                           GOD said   \n",
       "\n",
       "                                    Unnamed: 3  \\\n",
       "281                           why to miss them   \n",
       "1038                                        GE   \n",
       "2255  i wil tolerat.bcs ur my someone..... But   \n",
       "3525                            TX 4 FONIN HON   \n",
       "4668          \\\"OH No! COMPETITION\\\". Who knew   \n",
       "\n",
       "                                             Unnamed: 4  \n",
       "281                       just Keep-in-touch\\\" gdeve..\"  \n",
       "1038                                            GNT:-)\"  \n",
       "2255   Never comfort me with a lie\\\" gud ni8 and swe...  \n",
       "3525                CALL 2MWEN IM BK FRMCLOUD 9! J X\\\"\"  \n",
       "4668    one day these two will become FREINDS FOREVER!\"  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Unnamed: 4'].isnull() == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e6f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "#the unknown columns are sparsely populated and most that are are populated appear to contain irrelevant information \n",
    "#(such as time or address info).  droping these columns\n",
    "to_drop = ['Unnamed: 2',\"Unnamed: 3\",\"Unnamed: 4\"]\n",
    "df = df.drop(columns = to_drop)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b269d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   label      5572 non-null   object\n",
      " 1   documents  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#renamining columns\n",
    "rename_list = {'v1':'label','v2':'documents'}\n",
    "df = df.rename(columns=rename_list)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6f0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neither column has any null values, but lets check to make sure there is non-blank text in the documents\n",
    "df_temp = df['documents'].str.len() - df['documents'].str.count(' ')\n",
    "sum(df_temp == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ea9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "#okay so all the documents contain at least some characters.  Lets check that our label is a binary indicator as expected\n",
    "label_list = df.label.unique()\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d647401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating one hotkey on label\n",
    "label_binary = pd.get_dummies(df.label)\n",
    "label_binary= label_binary.drop(columns='ham')\n",
    "label_binary = label_binary.rename(columns={'spam':'label_binary'})\n",
    "df = pd.concat([df,label_binary],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106c070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 3)\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#checking hotkey join and binary hotkey labeling\n",
    "print(df.shape)\n",
    "print(df[df['label']=='ham'].label_binary.unique())\n",
    "print(df[df['label']=='spam'].label_binary.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86519632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac674c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping duplicated\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03b2ad",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "360f108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       documents  label_binary\n",
      "label                         \n",
      "ham         4516          4516\n",
      "spam         653           653\n"
     ]
    }
   ],
   "source": [
    "#looking at the frequency of ham versus spam\n",
    "label_count = df.groupby('label').count()\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f5d15a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5169\n"
     ]
    }
   ],
   "source": [
    "#lets look at how wordy our documents are - first creating a word count\n",
    "documents = df['documents'].tolist()\n",
    "word_count = [] \n",
    "for i in documents:\n",
    "    word_count.append(len(i.split()))\n",
    "print(len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3264a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>171.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>15.340685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std</td>\n",
       "      <td>11.067417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label       value\n",
       "0   min    1.000000\n",
       "1   max  171.000000\n",
       "2  mean   15.340685\n",
       "3   std   11.067417"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating mean, standard deviations, min, and max\n",
    "min_val = min(word_count)\n",
    "max_val =max(word_count)\n",
    "mean_val = np.mean(word_count)\n",
    "var_val = np.std(word_count)\n",
    "stat_label = pd.Series(('min','max','mean','std'))\n",
    "stats = pd.Series((min_val,max_val,mean_val,var_val))\n",
    "d = {'label':stat_label,'value':stats}\n",
    "df_stat = pd.DataFrame(data=d)\n",
    "df_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adee663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the word count into the data frame\n",
    "df['word_count'] = np.array(word_count)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdb06c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>documents</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yup</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thanx...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok..</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>ham</td>\n",
       "      <td>Beerage?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label documents  label_binary  word_count\n",
       "260   ham       Yup             0           1\n",
       "275   ham  Thanx...             0           1\n",
       "283   ham   Okie...             0           1\n",
       "286   ham      Ok..             0           1\n",
       "782   ham  Beerage?             0           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at a few of these one word documents\n",
    "df[df['word_count'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5099d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003869220352099052"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what percentage of the documents have only 1 word\n",
    "sum(df['word_count'] == 1)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8edca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 5169)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5eb1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the most common words - first prep a word list\n",
    "word_list = []\n",
    "for i in range(len(documents)):\n",
    "    word_list.append(documents[i].lower().split())\n",
    "master_word_list = list(itertools.chain(*word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d92ba3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 2095),\n",
       " ('to', 2055),\n",
       " ('you', 1832),\n",
       " ('a', 1281),\n",
       " ('the', 1223),\n",
       " ('and', 919),\n",
       " ('u', 890),\n",
       " ('in', 785),\n",
       " ('is', 766),\n",
       " ('my', 676),\n",
       " ('for', 653),\n",
       " ('your', 618),\n",
       " ('me', 579),\n",
       " ('of', 552),\n",
       " ('have', 532),\n",
       " ('on', 476),\n",
       " ('call', 468),\n",
       " ('are', 457),\n",
       " ('that', 453),\n",
       " ('it', 440)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now count the words\n",
    "count_words = collections.Counter(master_word_list)\n",
    "count_words.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b207acc",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ef7ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making text lowercase\n",
    "df['documents_clean'] = df['documents'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "971e3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CGLam\\AppData\\Local\\Temp\\ipykernel_184\\3020070343.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['documents_clean'] = df['documents_clean'].str.replace(r'https?://\\S+|www\\.\\S+', 'url')\n"
     ]
    }
   ],
   "source": [
    "#replacing URLs with keyword \"URL\"\n",
    "df['documents_clean'] = df['documents_clean'].str.replace(r'https?://\\S+|www\\.\\S+', 'url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f10b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\CGLam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#loading stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02eeb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "df['documents_clean'] = df['documents_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1393629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CGLam\\AppData\\Local\\Temp\\ipykernel_184\\2423228234.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['documents_clean'] = df['documents_clean'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "#remove punctuation\n",
    "df['documents_clean'] = df['documents_clean'].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e785dafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u', 1001),\n",
       " ('call', 487),\n",
       " ('im', 447),\n",
       " ('2', 443),\n",
       " ('get', 364),\n",
       " ('ur', 316),\n",
       " ('go', 269),\n",
       " ('4', 257),\n",
       " ('ltgt', 254),\n",
       " ('ok', 251),\n",
       " ('free', 243),\n",
       " ('know', 239),\n",
       " ('got', 231),\n",
       " ('like', 231),\n",
       " ('good', 217),\n",
       " ('come', 210),\n",
       " ('ill', 206),\n",
       " ('you', 200),\n",
       " ('time', 199),\n",
       " ('now', 198)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-reviewing most common words to see if it makes sense to create any custom stop words\n",
    "word_list_2 = []\n",
    "documents_2 = df['documents_clean'].tolist()\n",
    "for i in range(len(documents_2)):\n",
    "    word_list_2.append(documents_2[i].lower().split())\n",
    "master_word_list_2 = list(itertools.chain(*word_list_2))\n",
    "count_words_2 = collections.Counter(master_word_list_2)\n",
    "count_words_2.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "417a8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating custom stop words\n",
    "custom_stopwords = {'u','im','ur','ill','you'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08a75443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove custom stop words\n",
    "df['documents_clean'] = df['documents_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (custom_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67d04734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non-character tokens\n",
    "df['documents_clean'] = df['documents_clean'].apply(lambda x: ' '.join([word for word in x.split() if word.isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9a8b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['documents_clean'] = df['documents_clean'].apply(lambda x: ' '.join([stemmer.stem(y) for y in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e22fcfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>documents</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>word_count</th>\n",
       "      <th>documents_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>free entri wkli comp win fa cup final tkt may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>dun say earli hor c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          documents  label_binary  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...             0   \n",
       "1   ham                      Ok lar... Joking wif u oni...             0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...             1   \n",
       "3   ham  U dun say so early hor... U c already then say...             0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...             0   \n",
       "\n",
       "   word_count                                    documents_clean  \n",
       "0          20  go jurong point crazi avail bugi n great world...  \n",
       "1           6                                ok lar joke wif oni  \n",
       "2          28  free entri wkli comp win fa cup final tkt may ...  \n",
       "3          11                    dun say earli hor c alreadi say  \n",
       "4          13               nah think goe usf live around though  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acff91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export preprocessed data to excel for further review \n",
    "#df.to_excel('preprocessed.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538b9db",
   "metadata": {},
   "source": [
    "### Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47a66005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_tokenizer(x):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer\n",
    "    \n",
    "def encode(x2, tokenizer):\n",
    "    encoded_sentences = tokenizer.texts_to_sequences(x2)\n",
    "    encoded_sentences = tf.keras.preprocessing.sequence.pad_sequences(encoded_sentences, padding='post')\n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "489d1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = define_tokenizer(df['documents_clean'])\n",
    "s_strings = encode(df['documents_clean'],tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cded4e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking that we have appropriate number of documents\n",
    "len(s_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78447304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick look at encoding...text of first clean document\n",
    "df['documents_clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dfa9579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 2952,  271,  540,  568,  954,   43,   66,  325,  955,   88,\n",
       "       2089,  956,   11, 2953,   64,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding of that document\n",
    "s_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9903ce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2952\n",
      "271\n",
      "540\n",
      "568\n",
      "954\n",
      "43\n",
      "66\n",
      "325\n",
      "955\n",
      "88\n",
      "2089\n",
      "956\n",
      "11\n",
      "2953\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "#pulling these words out of the dictionary to make sure we encoded as expected\n",
    "d = tokenizer.word_index\n",
    "print(d['go'])\n",
    "print(d['jurong'])\n",
    "print(d['point'])\n",
    "print(d['crazi'])\n",
    "print(d['avail'])\n",
    "print(d['bugi'])\n",
    "print(d['n'])\n",
    "print(d['great'])\n",
    "print(d['world'])\n",
    "print(d['la'])\n",
    "print(d['e'])\n",
    "print(d['buffet'])\n",
    "print(d['cine'])\n",
    "print(d['got'])\n",
    "print(d['amor'])\n",
    "print(d['wat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83780414",
   "metadata": {},
   "source": [
    "### One Hotkey Encoding (Count Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "999ca2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the one hotkey on clean documents\n",
    "vec = CountVectorizer()\n",
    "X_train_count = vec.fit_transform(df['documents_clean'].values)\n",
    "X_train_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7bea37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#moving into pandas dataframe\n",
    "df_one = pd.DataFrame(X_train_count.toarray())\n",
    "len(df_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "758b9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one['y'] = df['label_binary'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c1d84",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11f3a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate depedendent and indepedent variables\n",
    "y = df_one['y']\n",
    "x = df_one.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "940ec84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d79fd5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Independent Variable Shape: (2584, 6793)\n",
      "Test Independent Variable Shape: (2585, 6793)\n",
      "Train Dependent Variable Shape: (2584,)\n",
      "Test Dependent Variable Shape: (2585,)\n"
     ]
    }
   ],
   "source": [
    "#checking shape of test train splits\n",
    "print(\"Train Independent Variable Shape:\",x_train.shape)\n",
    "print(\"Test Independent Variable Shape:\",x_test.shape)\n",
    "print(\"Train Dependent Variable Shape:\",y_train.shape)\n",
    "print(\"Test Dependent Variable Shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da7e1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "x_train.to_csv(\"Data/x_train.csv\",index=False)\n",
    "x_test.to_csv(\"Data/x_test.csv\",index=False)\n",
    "y_train.to_csv(\"Data/y_train.csv\",index=False)\n",
    "y_test.to_csv(\"Data/y_test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
